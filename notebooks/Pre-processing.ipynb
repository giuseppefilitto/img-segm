{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, shutil\n",
    "sys.path.append('../')\n",
    "\n",
    "from MRIsegm.utils import get_slice, get_slice_info, get_rois, explore_slice, explore_roi, make_mask, mask_slice\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "from time import sleep\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good patiences: 36\n"
     ]
    }
   ],
   "source": [
    "src = '/Users/giuseppefilitto/Pazienti_anonym_sorted'\n",
    "\n",
    "patiences = os.listdir(src)\n",
    "if '.DS_Store' in patiences:\n",
    "    patiences.remove('.DS_Store')\n",
    "\n",
    "bad_patiences = [ 'BO9', 'BO17', 'BO28', 'BO36', 'BO37', 'BO39', 'BO40', 'BO54', 'BO72', 'BO77', 'BO86']\n",
    "\n",
    "good_patiences = list(set(patiences) - set(bad_patiences))\n",
    "\n",
    "# ! Removing for now \n",
    "good_patiences.remove('BO38')\n",
    "print(\"Number of good patiences:\",len(good_patiences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Train and Test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4a6a7494bf471d898165639a008dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Progress:   0%|          | 0/36 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = trange(len(good_patiences), desc=\"Progress\")\n",
    "for patience in good_patiences:\n",
    "\n",
    "    #! slices\n",
    "    folder = 'T2'\n",
    "    slice_path = os.path.join(src, patience, folder)\n",
    "\n",
    "    if not os.path.isdir(slice_path):\n",
    "        slice_path =  slice_path + \"AX\"\n",
    "\n",
    "        if not os.path.isdir(slice_path):\n",
    "            slice_path = os.path.join(src, patience, 'T25mm')\n",
    "\n",
    "            if not os.path.isdir(slice_path):\n",
    "                slice_path = os.path.join(src, patience, 't2DEF')\n",
    "\n",
    "\n",
    "    slice = get_slice(dir_path=slice_path)  \n",
    "    \n",
    "\n",
    "    roi_folder = 'T2ROI'\n",
    "    roi_path = os.path.join(src, patience, roi_folder)\n",
    "\n",
    "    #! ROIS\n",
    "    roi = get_rois(roi_path=roi_path)\n",
    "    \n",
    "\n",
    "    #! slices of masks\n",
    "\n",
    "    slice_of_masks = mask_slice(slice=slice, rois=roi)\n",
    "    \n",
    "\n",
    "    positions = [roi[j].get('position') - 1 for j in range(len(roi))]\n",
    "\n",
    "    \n",
    "    for i in set(positions):\n",
    "\n",
    "        img = Image.fromarray(slice[i, : ,:])\n",
    "        filename = patience + '_slice_' + str(i) + '.png'\n",
    "        dst = '../data/train/slices'\n",
    "        output =  os.path.join(dst, filename)\n",
    "\n",
    "        if os.path.isfile(output):\n",
    "            os.remove(output)\n",
    "        \n",
    "        img.save(output)\n",
    "\n",
    "        mask = Image.fromarray(slice_of_masks[i, : ,:])\n",
    "        filename = patience + '_mask_' + str(i) + '.png'\n",
    "        dst = '../data/train/masks'\n",
    "        output =  os.path.join(dst, filename)\n",
    "        if os.path.isfile(output):\n",
    "            os.remove(output)\n",
    "\n",
    "        mask.save(output)\n",
    "\n",
    "        \n",
    "           \n",
    "    sleep(0.01)\n",
    "    progress_bar.update(1)    \n",
    "\n",
    "progress_bar.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images 469\n",
      "Test images 93\n"
     ]
    }
   ],
   "source": [
    "train_dir = '../data/train/slices'\n",
    "train_files = glob.glob(train_dir + '/*.png')\n",
    "\n",
    "mask_dir = '../data/train/masks'\n",
    "mask_files = glob.glob(mask_dir + '/*.png')\n",
    "\n",
    "print(\"Training images\", len(train_files))\n",
    "# ! test\n",
    "\n",
    "test_dir = '../data/test/slices'\n",
    "ground_truth_dir = '../data/test/ground truth'\n",
    "\n",
    "n_test = int(len(train_files) * 0.2)\n",
    "print(\"Test images\", n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,n_test + 1):\n",
    "    \n",
    "    dir, file = os.path.split(train_files[i])\n",
    "    test_path = os.path.join(test_dir, file)\n",
    "\n",
    "    img = train_files[i]\n",
    "    shutil.move(img, test_path)\n",
    "\n",
    "    mask_dir = dir.replace('slices', 'masks')\n",
    "    mask_file = file.replace('_slice_','_mask_')\n",
    "    \n",
    "    mask = os.path.join(mask_dir, mask_file)\n",
    "    gt_path = os.path.join(ground_truth_dir, file)\n",
    "    shutil.move(mask, gt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python391jvsc74a57bd0b006050eb1e698e71d69e874d7b73cfc81eadd7038d8c48e3a55c8dc4f112791"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "b006050eb1e698e71d69e874d7b73cfc81eadd7038d8c48e3a55c8dc4f112791"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}